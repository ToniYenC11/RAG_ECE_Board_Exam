{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891ee456",
   "metadata": {},
   "source": [
    "# Retrival-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec824963",
   "metadata": {},
   "source": [
    "## Components of RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d49590",
   "metadata": {},
   "source": [
    "- **Retrieval Engine** - Search and rank data based on a query. \n",
    "    - **Input Query Processor** - Interpret and refine user input.\n",
    "\n",
    "    - **Search Engine** - Searches indexed data using a model (i.e. SEntence Transformers) then ranks the embeddings using another model (i.e. Elastisearch KNN)\n",
    "\n",
    "- **Augmentation Engine** - Takes the top-ranked data from retrieval engine and adds to **prompt**, that will be def to the LLM.\n",
    "\n",
    "- **Generation Engine** - AAdvanced LLM. Creates a response by combining its language skills with the newly retrieved external data that is used as a prompt addition to the LLM.\n",
    "     - Allows generation of response that is coherent, up-to-date, and relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ec801",
   "metadata": {},
   "source": [
    "## [Step-by-Step of a RAG](https://www.linkedin.com/pulse/how-rag-works-detailed-explanation-its-components-steps-pradeep-menon-ws7sc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fa293",
   "metadata": {},
   "source": [
    "### **Data-indexing** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58b323",
   "metadata": {},
   "source": [
    "- The data that needs to be ingested, be it documents, images etc. is processed and chunked. Then the data is indexed using an indexing strategy.\n",
    "- The step of data indexing is performed periodically as and when new data needs to be used for response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d7be1",
   "metadata": {},
   "source": [
    "- ***Search Indexing*** - Used when the data is indexed by exact matches of words or phrases. \n",
    "    - Fast and precise, but can miss relevant data when not matched exactly.\n",
    "\n",
    "- ***Vector Indexing*** - Used when data is indexed by numerical vectors representing meaning of words or phrases.\n",
    "    - Slower and less precise, but can find more relevant data that is not an exact match.\n",
    "\n",
    "- ***Hybrid indexing*** - Indexed by both eaxt matches and numerical vectors. Hybrid indexing can improve the accuracy and diversity of data retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a714394",
   "metadata": {},
   "source": [
    "### **Input Query Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1d356",
   "metadata": {},
   "source": [
    "- Fine-tuning the question to improve its compatibility with the indexed data. The question is simplified and optimized for effective search.\n",
    "\n",
    "- *Search indexing*: Undegoes simple text processing to remove stopwords, or simply use the question as it is.\n",
    "\n",
    "- *Vector indexing*: IQP is more complex and complicated:\n",
    "    - The input query is transformed into a **vector** using neural network techniques like encoding.\n",
    "\n",
    "    - This transformation captures its **semantic similarity** (i.e. SBERT). \n",
    "\n",
    "- **Hybrid indexing** - Here, the input query processing can be a combination of search and vector indexing.\n",
    "    - The query processing can involve using the question as is or removing some stop words to make it more concise\n",
    "\n",
    "    - Then, a neural network can be used to encode the query into a vector that captures its semantic similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bc37b",
   "metadata": {},
   "source": [
    "### **Search and Ranking**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90744e5",
   "metadata": {},
   "source": [
    "- The query, which can be a word, a phrase, or a vector, is used to search the indexed data, which can be exact matches or numerical vectors \n",
    "- The search returns a list of data that are relevant to the query.\n",
    "- The search result is further used by RAG to generate response that is responsive and useful for the users\n",
    "- RAG can use different algorithms for text search depending on the type of indexing and the type of query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1c8b2",
   "metadata": {},
   "source": [
    "- *Search Indexing*\n",
    "    - **TF-IDF** (Term Frequency-Inverse Document Frequency): Ranks the documents based on how often the quer term appears.\n",
    "    - **BM25** - Ab etter version of TF-IDF. COnsiders how often a term appears and how long a document is, giving a more advanced ordering of search results.\n",
    "\n",
    "- *Vector Indexing*\n",
    "    - **Word Embeddings** (Word2Vec, GloVe) - Converts words into dense vectors that capture meanings, used for understanding word context and relationships.\n",
    "    - **Cosine Similarity** - Measures the cosine of the angle between two vectors, used to determine query vector similarity to document vectors.\n",
    "    - **SBERT** - Integrates Cosine Similarity to standard BERT model.\n",
    "\n",
    "- *Hybrid Indexing* utilizes both algorithmically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b8084",
   "metadata": {},
   "source": [
    "### **Prompt Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c288f",
   "metadata": {},
   "source": [
    "- We add the best pieces of information to the original question to enhance the prompt.\n",
    "- This step ensures that the LLM's response is not solely reliant on its pre-existing knowledge. The response is also tailored with up-to-date and specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30542bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Generate me 5 questions for ESAT (Knowledge).\n",
    "\n",
    "Additional information:\n",
    "<information>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c555b",
   "metadata": {},
   "source": [
    "### **Response Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d183b1",
   "metadata": {},
   "source": [
    "- LLM uses the augmented prompt to create a response. \n",
    "- The answer is ***grounded*** on the specific, current data obtained earlier.\n",
    "- The LLM combines its own knowledge with external data to create precise and relevant responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c8d20",
   "metadata": {},
   "source": [
    "## RAG Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea38fbb4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
